aiAssistantLicense:
  activationKey: ""
  externalSecret:
    name: ""
    key: AI_ASSISTANT_ACTIVATION_KEY

apiAuth:
  apiToken: secret
  jwt:
    publicKey: none
    algorithm: RS256

# This is only necessary until `openai-mock` supports text embeddings
sidecars:
  - name: openai-mocker
    image: python:3.11-alpine
    imagePullPolicy: IfNotPresent
    command:
      - /bin/sh
      - -ce
      - |-
        cat > /tmp/embeddings-mock.py << 'EOF'
        import uvicorn
        from fastapi import FastAPI
        from pydantic import BaseModel
        from typing import List, Union
        import random

        app = FastAPI()

        class EmbeddingRequest(BaseModel):
            input: Union[str, List[str]]
            model: str = "text-embedding-3-small"

        @app.post("/v1/embeddings")
        async def create_embeddings(request: EmbeddingRequest):
            inputs = request.input if isinstance(request.input, list) else [request.input]
            embeddings = []
            for i, text in enumerate(inputs):
                embedding = [random.uniform(-1, 1) for _ in range(1536)]
                embeddings.append({
                    "object": "embedding",
                    "index": i,
                    "embedding": embedding
                })
            return {
                "object": "list",
                "data": embeddings,
                "model": request.model,
                "usage": {
                    "prompt_tokens": sum(len(text.split()) for text in inputs),
                    "total_tokens": sum(len(text.split()) for text in inputs)
                }
            }

        if __name__ == "__main__":
            uvicorn.run(app, host="0.0.0.0", port=8080)
        EOF

        pip install fastapi uvicorn && python /tmp/embeddings-mock.py

config:
  serviceConfiguration:
    version: '1'
    aiServices:
      chat:
        provider:
          name: 'openai-compat'
          baseUrl: 'https://api.openai-mock.com'
        model: 'gpt-4'
      textEmbeddings:
        provider:
          name: 'openai-compat'
          # `openai-mock` does not yet support text embeddings
          baseUrl: 'http://localhost:8080/v1'
        model: 'text-embedding-3-small'
  documentEngine:
    enabled: true
    url: http://document-engine:5000
    auth:
      apiToken: documentEngineSecret

database:
  enabled: true
  engine: postgres
  postgres:
    username: postgres
    password: nutrientArtificialIntelligenceAssistant
    tls:
      enabled: false

dashboard:
  auth:
    username: admin
    password: admin

observability:
  log:
    level: info
    socketTraces: false
  opentelemetry:
    enabled: false

replicaCount: 1

updateStrategy:
  type: RollingUpdate
  rollingUpdate:
    maxUnavailable: 1
    maxSurge: 0

resources:
  requests:
    cpu: "100m"
    memory: 256Mi
  limits:
    cpu: "2"
    memory: 4Gi

ingress:
  enabled: true
  className: nginx
  annotations:
    nginx.ingress.kubernetes.io/backend-protocol: "HTTP"
    nginx.ingress.kubernetes.io/rewrite-target: /
    nginx.ingress.kubernetes.io/proxy-body-size: "0"
    nginx.ingress.kubernetes.io/proxy-send-timeout: "180"
    nginx.ingress.kubernetes.io/proxy-read-timeout: "180"
    nginx.ingress.kubernetes.io/large-client-header-buffers: "4 16k"
    nginx.ingress.kubernetes.io/proxy-buffer-size: "128k"
  hosts:
    - paths:
        - path: /
          pathType: ImplementationSpecific

cloudNativePG:
  enabled: true
  clusterName: "{{ .Release.Name }}-postgres"
  documentEngineDatabase: 
    enabled: true
    name: document_engine

document-engine:
  enabled: true
  fullnameOverride: document-engine
  nameOverride: document-engine
  documentEngineLicense:
    activationKey: ""
    externalSecret:
      name: ""
  apiAuth:
    apiToken: documentEngineSecret
  config:
    trustedProxies: default
  documentSigningService:
    enabled: false
  database:
    enabled: true
    engine: postgres
    migrationJob:
      enabled: false
    postgres:
      host: "{{ .Release.Name }}-postgres-rw"
      database: document_engine
      username: postgres
      password: nutrientArtificialIntelligenceAssistant
      adminUsername: postgres
      adminPassword: nutrientArtificialIntelligenceAssistant
      tls:
        enabled: false
  assetStorage:
    backendType: built-in
    backendFallback:
      enabled: false
  dashboard:
    auth:
      username: admin
      password: admin
  observability:
    log:
      level: info
    opentelemetry:
      enabled: false
  replicaCount: 1
  updateStrategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1
      maxSurge: 0
  resources:
    requests:
      cpu: "100m"
      memory: 256Mi
    limits:
      cpu: "2"
      memory: 4Gi
  ingress:
    enabled: true
    className: nginx
    annotations:
      nginx.ingress.kubernetes.io/backend-protocol: "HTTP"
      nginx.ingress.kubernetes.io/rewrite-target: /
      nginx.ingress.kubernetes.io/proxy-body-size: "0"
      nginx.ingress.kubernetes.io/proxy-send-timeout: "180"
      nginx.ingress.kubernetes.io/proxy-read-timeout: "180"
      nginx.ingress.kubernetes.io/large-client-header-buffers: "4 16k"
      nginx.ingress.kubernetes.io/proxy-buffer-size: "128k"
    hosts:
      - paths:
          - path: /
            pathType: ImplementationSpecific
  startupProbe:
    initialDelaySeconds: 30
  cloudNativePG:
    enabled: false
